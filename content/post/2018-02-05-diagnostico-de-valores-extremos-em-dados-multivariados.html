---
title: Diagnóstico de valores extremos em dados multivariados
author: Melina de Souza Leite
date: '2018-02-05'
bibliography: "../../data/2018-02-05-diagnóstico-de-valores-extremos-em-dados-multivariados/refs.bib"
slug: diagnóstico-de-valores-extremos-em-dados-multivariados
categories:
  - R
tags:
  - Análise_exploratória
  - Multivariada
  - plot
---



<p>Uma das maneiras mais comuns de se observar valores extremos (<em>outliers</em>) em nossos dados é usar o gráfico de <a href="https://pt.wikipedia.org/wiki/Diagrama_de_caixa">boxplot</a> em cada variável de interesse (veja no link como o boxplot é usado para classificar valores extremos).</p>
<p>Entretanto, quando temos dados multivariados é interessante observar os valores extremos de maneira conjunta, isto é, levando em consideração todas as variáveis dos dados. Neste caso, os boxplots univariados não nos servem mais<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. Detectar valores extremos em observações univariadas é diferente de detectá-los de maneira multivariada e o que era um <em>outlier</em> em uma variável pode não ser mais num contexo multivariado e vice-versa.</p>
<p>Neste roteiro, apresento os <strong>boxplots bivariados</strong> do pacote <code>MVA</code>, descritos em <span class="citation">Everitt and Hothorn (2011)</span> e o uso da <strong>Distância de Mahalanobis</strong> de cada observação ao centróide dos dados para diagnóstico de valores extremos.</p>
<div id="boxplots-em-um-exemplo-bivariado" class="section level1">
<h1>Boxplots em um exemplo bivariado</h1>
<p>Vamos usar um exemplo com apenas duas variáveis para facilitar a inspeção visual.</p>
<p>Escolhemos duas variáveis do conjunto de dados <code>swiss</code> do pacote <code>datasets</code><a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> e vamos primeiro inspecioná-las separadamente com os boxplots univariados.</p>
<pre class="r"><code># para determinar as observações outiers a serem nomeadas no plot
out &lt;- function(x) {
  return(x &lt; quantile(x, 0.25) - 1.5 * IQR(x) | 
           x &gt; quantile(x, 0.75) + 1.5 * IQR(x))
}
# OBS: é o critério usado na identificação dos oultiers nos boxplots</code></pre>
<pre class="r"><code>par(mfrow=c(1,2))
boxplot(swiss$Examination, main = &quot;Examination&quot;)
boxplot(swiss$Education, main = &quot;Education&quot;)
text(x=c(1,1,1,0.8,1.2), 
           y=swiss[out(swiss[,4]),4]-c(3,-2,2,1,-1), 
           label= rownames(swiss[out(swiss[,4]),]))
par(mfrow=c(1,1))</code></pre>
<p><img src="/post/2018-02-05-diagnostico-de-valores-extremos-em-dados-multivariados_files/figure-html/fig1-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Para <code>Examination</code> não encontramos outliers segundo o método do boxplot, mas para <code>Education</code> temos 5 valores extremos.</p>
<p>Vamos agora desenhar um <strong>boxplot bivariado</strong> conforme <span class="citation">Everitt and Hothorn (2011)</span>. Os boxplots bivariados são baseados nos cálculos “robustos” das medidas de locação, escala e correlação e consiste em um par de elipses concêntricas, uma das quais inclui 50% dos dados e a outra que delinea o limite dos dados e deixa de fora os possíveis <em>outliers</em>. Também são desenhadas linhas de regressão de x em y e de y em x, com sua interseção mostrando o parâmetro de locação (média das duas variáveis). O ângulo entre as linhas de regressão serão tão pequenos quanto maior for a correlação entre as variáveis.</p>
<p>Vamos usar a função <code>bvbox</code> do pacote <code>MVA</code> que acompanha o livro de <span class="citation">Everitt and Hothorn (2011)</span>, para observar a relação entre as variáveis.</p>
<pre class="r"><code>library(MVA)
bvbox(swiss[,c(3,4)], xlab = colnames(swiss)[3], 
      ylab = colnames(swiss)[4])
text(x = swiss[out(swiss[,4]),3], 
     y = swiss[out(swiss[,4]),4]-2.5, 
     rownames(swiss[out(swiss[,4]),]))</code></pre>
<p><img src="/post/2018-02-05-diagnostico-de-valores-extremos-em-dados-multivariados_files/figure-html/fig2-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>No boxplot bivariado, detectamos os mesmos <em>outliers</em> encontrados apenas em <code>Education</code>.</p>
<p>A desvantagem dos boxplots bivariados é que eles avaliam os outliers apenas para duas variáveis por vez e geralmente temos mais do que duas variáveis nos nossos dados. A seguir veremos uma forma mais geral de se avaliar os valores extremos multivariados.</p>
</div>
<div id="usando-a-distancia-de-mahalanobis" class="section level1">
<h1>Usando a distância de Mahalanobis</h1>
<p>A <strong>distância de Mahalanobis</strong> (<span class="math inline">\(D^2_M\)</span>) é uma medida de distância entre as observações (unidades amostrais) e pode também ser usada para medir a distância entre uma única observação multivariada e o centro da população (multivariado não se esqueça), da qual esta esta observação vem (<span class="citation">Manly and Navarro Alberto (2017)</span>). No nosso caso, vamos calcular a distância da observação ao centróide da distribuição dos dados.</p>
<p>O <a href="https://en.wikipedia.org/wiki/Mahalanobis_distance">cálculo da distância de Mahalanobis</a> leva em consideração a correlação entre as variáveis, e seu valor <span class="math inline">\(D^2_M\)</span> pode ser pensado como um resíduo multivariado para a observação <span class="math inline">\(x\)</span>. <span class="math inline">\(D^2_M\)</span> é uma medida de quão longe a obervação <span class="math inline">\(x\)</span> está do centro da distribuição de todos os valores, levando em consideração todas as variáveis consideradas e suas covariâncias (<span class="citation">Manly and Navarro Alberto (2017)</span>). Um valor alto de <span class="math inline">\(D^2_M\)</span> para a observação <span class="math inline">\(x\)</span> pode indicar um possível <em>outlier</em> multivariado, se excluímos a possibilidade de erro de digitação/registro ou que a observação seja de outra distribuição.</p>
<p>Vamos calcular <span class="math inline">\(D^2_M\)</span> para cada observação dos dados apresentados acima, e plotar estas distâncias. Um critério para o diagnóstico dos outliers a partir da distância de Mahalanobis é verificar se a distância calculada está acima de um limiar <span class="math inline">\(c^2\)</span>, que nada mais é do que a estatística do Qui-quadrado (<span class="math inline">\(\chi^2\)</span>) calculada para um valor de probabilidade escolhido. No exemplo abaixo, eu escolhi um <span class="math inline">\(\alpha\)</span> de 10% e fui na distribuição de (<span class="math inline">\(\chi^2\)</span>) com 2 graus de liberdade (g.l. = número de variáveis sendo analisadas) saber qual é o quantil e desenhei a linha pontilhada no gráfico com este valor.</p>
<pre class="r"><code>maha &lt;- mahalanobis(swiss[,3:4], # dados
          center = colMeans(swiss[,3:4]), # médias das variáveis
          cov = cov(swiss[,3:4])) # matriz de covariâncias

#calculando o cˆ2 para delimitar o limiar
quant &lt;- qchisq(0.1, 2, lower.tail = F)

plot(1:length(maha), maha, xlab = &quot;Observações&quot;, 
     ylab= &quot;Distância de Mahalanobis&quot;)
abline(h=quant, lty=2)

out &lt;- maha[maha&gt;quant]
text(c(42,44,46,48)-7, out, names(out))</code></pre>
<p><img src="/post/2018-02-05-diagnostico-de-valores-extremos-em-dados-multivariados_files/figure-html/fig3-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Desta forma, para o critério usando a distância de Mahalanobis, 4 observações foram consideradas <em>outliers</em> bivariados. Este critério está dizendo que as 4 observações com maior distância tem pouca probabilidade de serem advindas da população com distribuição normal bivariada assumida nos dados.</p>
</div>
<div id="diagnosticando-outliers-multivariados" class="section level1">
<h1>Diagnosticando <em>outliers</em> multivariados</h1>
<p>Agora vamos expandir nosso exemplo usando todas as variáveis existentes nos dados <code>swiss</code>. Aqui eu não vou fazer os boxplots bivariados (você já sabe como faz), mas quero apenas mostrar o plot da distância de Mahalanobis para ver se, com mais variáveis, temos diferentes outliers detectados.</p>
<pre class="r"><code>maha2 &lt;- mahalanobis(swiss, center = colMeans(swiss), 
                     cov = cov(swiss))

# lembre-se que os graus de liberdade agora são 6
quant2 &lt;- qchisq(0.90, 6)

plot(1:length(maha2), maha2, xlab = &quot;Observações&quot;, 
     ylab = &quot;Distância de Mahalanobis&quot;)
abline(h = quant2, lty = 2)

out2 &lt;- maha2[maha2 &gt; quant2]
text(c(2.5,15,34,38,40,44), out2, names(out2))</code></pre>
<p><img src="/post/2018-02-05-diagnostico-de-valores-extremos-em-dados-multivariados_files/figure-html/fig4-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Com mais variáveis, tivemos diferentes observações detectadas como <em>outliers</em> e por isso a importância de se analisar os valores extremos em dados multivariados de maneira conjunta!</p>
<div id="usando-pacote-mvn" class="section level2">
<h2>Usando pacote <code>MVN</code></h2>
<p>O pacote <code>MVN</code> possui uma função que também detecta <em>outliers</em> multivariados a partir da <strong>distância de Mahalanobis</strong>. Esse pacote usa dois métodos <em>robustos</em> (ver detales <a href="https://pdfs.semanticscholar.org/5508/25b2681f1cc067c66df6ddbd62c74b441869.pdf?_ga=2.25175998.286279602.1517010562-1528935492.1517010562">aqui</a>) para calcular a distância de Mahalanobis (a distância de Mahalanobis Robusta e a Ajustada), e portanto dão resultados um pouco diferentes do que fizemos anteriormente.</p>
<p>Outra diferença é que resultado é apresentado em um gráfico quantil-quantil (<em>qqplot</em>), com um dos eixos sendo a <span class="math inline">\(D^2_M\)</span> e o outro os quantis de uma distribuição <span class="math inline">\(\chi^2\)</span>.</p>
<pre class="r"><code>library(MVN)

outliers &lt;- mvOutlier(swiss, alpha = 0.90, method = &quot;quan&quot;) 
# tente method=&quot;adj.quan&quot;</code></pre>
<p><img src="/post/2018-02-05-diagnostico-de-valores-extremos-em-dados-multivariados_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="observacoes-finais" class="section level1">
<h1>Observações finais</h1>
<p>Vale lembrar que estes valores extremos não necessariamente são erros de digitação/medida, mas podem ser valores reais, porém pouco prováveis. A decisão sobre o que fazer com estes <em>possíveis outliers</em> detectados depende muito da natureza dos dados, do contexto de coleta dos dados e do tipo de análise a ser conduzida.</p>
<p>Uma sugestão feita por <span class="citation">Manly and Navarro Alberto (2017)</span> é a de conduzir análises com e sem os valores extremos e comparar os resultados. Se a conclusão é a mesma, então não há problemas. Mas se as conclusões dependem muito dos <em>outliers</em>, então é preciso muito mais cuidado com as decisões a serem tomadas.</p>
</div>
<div id="referencias" class="section level1 unnumbered">
<h1>Referências</h1>
<div id="refs" class="references">
<div id="ref-everitt_introduction_2011">
<p>Everitt, B, and T Hothorn. 2011. <em>An Introduction to Applied Multivariate Analysis with R</em>.</p>
</div>
<div id="ref-manly_multivariate_2017">
<p>Manly, Bryan F. J., and Jorge A. Navarro Alberto. 2017. <em>Multivariate Statistical Methods: A Primer</em>. Fourth edition. Boca Raton: CRC Press.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>eles também não servem se a quantidade de dados for muito grande, veja <a href="https://melinaleiteblog.netlify.com/2018/01/20/alternativas-visualizar-dados/">esse roteiro</a> sobre gráficos alternativos aos boxplots nessa situação.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>que não precisa ser carregado porque já vem junto como R base.<a href="#fnref2">↩</a></p></li>
</ol>
</div>
